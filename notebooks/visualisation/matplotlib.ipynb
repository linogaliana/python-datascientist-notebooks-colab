{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Construire des graphiques avec Python\n",
        "\n",
        "Lino Galiana  \n",
        "2025-06-14\n",
        "\n",
        "<div class=\"badge-container\"><div class=\"badge-text\">Pour essayer les exemples présents dans ce tutoriel :</div><a href=\"https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/visualisation/matplotlib.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/static/v1?logo=github&label=&message=View%20on%20GitHub&color=181717\" alt=\"View on GitHub\"></a>\n",
        "<a href=\"https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=true&name=«matplotlib»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-vscode.sh»&init.personalInitArgs=«visualisation%20matplotlib%20correction»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://custom-icon-badges.demolab.com/badge/SSP%20Cloud-Lancer_avec_VSCode-blue?logo=vsc&logoColor=white\" alt=\"Onyxia\"></a>\n",
        "<a href=\"https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&name=«matplotlib»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-jupyter.sh»&init.personalInitArgs=«visualisation%20matplotlib%20correction»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/SSP%20Cloud-Lancer_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"></a>\n",
        "<a href=\"https://colab.research.google.com/github/linogaliana/python-datascientist-notebooks-colab//blob/main//notebooks/visualisation/matplotlib.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a><br></div>\n",
        "\n",
        "La pratique de la *data visualisation* se fera, dans ce cours, en répliquant des graphiques qu’on peut trouver sur\n",
        "la page de l’*open data* de la ville de Paris\n",
        "[ici](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/dataviz/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name) ou en proposant des alternatives à ceux-ci sur les mêmes données.\n",
        "\n",
        "L’objectif de ce chapitre n’est pas de faire un inventaire complet des graphiques pouvant être fait avec `Python`, ce serait long, assez insipide et peu pertinent car des sites le font déjà très bien à partir d’une grande variété d’exemple, notamment le site [python-graph-gallery.com/](https://python-graph-gallery.com/). L’objectif est plutôt d’illustrer, par la pratique, quelques enjeux liés à l’utilisation des principales librairies graphiques de `Python`.\n",
        "\n",
        "On peut distinguer quelques grandes familles de représentations graphiques: les représentations de distributions propres à une variable, les représentations de relations entre plusieurs variables, les cartes qui permettent de représenter dans l’espace une ou plusieurs variables…\n",
        "\n",
        "Ces familles se ramifient elles-mêmes en de multiples types de figures. Par exemple, selon la nature du phénomène, les représentations de relations peuvent prendre la forme d’une série temporelle (évolution d’une variable dans le temps), d’un nuage de point (corrélation entre deux variables), d’un diagramme en barre (pour souligner le rapport relatif entre les valeurs d’une variable en fonction d’une autre), etc.\n",
        "\n",
        "Plutôt qu’un inventaire à la Prévert des types de visualisations possibles, ce chapitre et le suivant vont plutôt proposer quelques visualisations qui pourraient donner envie d’aller plus loin dans l’analyse avant la mise en oeuvre d’une forme de modélisation. Ce chapitre est consacré aux visualisations traditionnelles, le [suivant](../../content/visualisation/maps.qmd) est dédié à la cartographie. Ces deux chapitres font partie d’un tout visant à offrir les premiers éléments pour synthétiser l’information présente dans un jeu de données.\n",
        "\n",
        "Le pas suivant est d’approfondir le travail de communication et de synthèse par le biais de communications pouvant prendre des formes aussi diverses que des rapports, des publications scientifiques ou articles, des présentations, une application interactive, un site web ou des *notebooks* comme ceux proposés par ce cours. Le principe général est identique quelle que soit le *medium* utilisé et intéresse particulièrement les *data scientists* lorsqu’ils font appel à de l’exploitation intensive de données. Ce sera l’objet d’un chapitre futur de ce cours[1].\n",
        "\n",
        "# 1. Données\n",
        "\n",
        "Ce chapitre s’appuie sur les données de comptage des passages de vélo dans les points de mesure parisiens diffusés sur le site de l’*open data* de la ville de Paris.\n",
        "\n",
        "L’exploitation de l’historique récent a été grandement facilité par la diffusion des données au format `Parquet`, un format moderne plus pratique que le CSV. Pour en savoir plus sur ce format, vous pouvez consulter les ressources évoquées dans le paragraphe consacré à ce format dans le [chapitre d’approfondissement](../../content/manipulation/02_pandas_suite.qmd).\n",
        "\n",
        "[1] This chapter will be built around the [`Quarto`](https://quarto.org/) ecosystem. In the meantime, you can consult the excellent documentation of this ecosystem and practice, which is the best way to learn."
      ],
      "id": "7fde560c-0f3f-41af-88df-ff27b0c3f4a0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import duckdb\n",
        "\n",
        "url = \"https://minio.lab.sspcloud.fr/lgaliana/data/python-ENSAE/comptage-velo-donnees-compteurs.parquet\"\n",
        "# problem with https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/comptage-velo-donnees-compteurs/exports/parquet?lang=fr&timezone=Europe%2FParis\n",
        "\n",
        "filename = 'comptage_velo_donnees_compteurs.parquet'\n",
        "\n",
        "\n",
        "# DOWNLOAD FILE --------------------------------\n",
        "\n",
        "# Perform the HTTP request and stream the download\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    # Perform the HTTP request and stream the download\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Get the total size of the file from the headers\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        # Open the file in write-binary mode and use tqdm to show progress\n",
        "        with open(filename, 'wb') as file, tqdm(\n",
        "                desc=filename,\n",
        "                total=total_size,\n",
        "                unit='B',\n",
        "                unit_scale=True,\n",
        "                unit_divisor=1024,\n",
        "        ) as bar:\n",
        "            # Write the file in chunks\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:  # filter out keep-alive chunks\n",
        "                    file.write(chunk)\n",
        "                    bar.update(len(chunk))\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "else:\n",
        "    print(f\"The file '{filename}' already exists.\")\n",
        "\n",
        "# READ FILE AND CONVERT TO PANDAS --------------------------\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT id_compteur, nom_compteur, id, sum_counts, date\n",
        "FROM read_parquet('comptage_velo_donnees_compteurs.parquet')\n",
        "\"\"\"\n",
        "\n",
        "# READ WITH DUCKDB AND CONVERT TO PANDAS\n",
        "df = duckdb.sql(query).df()\n",
        "\n",
        "df.head(3)"
      ],
      "id": "download-bike-data"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Premières productions graphiques avec l’API `Matplotlib` de `Pandas`\n",
        "\n",
        "Chercher à produire une visualisation parfaite du premier coup est illusoire. Il est beaucoup plus réaliste d’améliorer graduellement une représentation graphique afin, petit à petit, de mettre en avant les effets de structure dans un jeu de données.\n",
        "\n",
        "Nous allons donc commencer par nous représenter la distribution des passages aux principales stations de mesure. Pour cela nous allons produire rapidement un *barplot* puis l’améliorer graduellement.\n",
        "\n",
        "Dans cette partie, nous allons ainsi reproduire les deux premiers graphiques de la [page d’analyse des données](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/dataviz/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name) : *Les 10 compteurs avec la moyenne horaire la plus élevée* et *Les 10 compteurs ayant comptabilisé le plus de vélos*. Les valeurs chiffrées des graphiques peuvent être différentes de celles de la page en ligne, c’est normal, car nous ne travaillons pas systématiquement sur les données ayant la même fraîcheur que celles en ligne.\n",
        "\n",
        "Pour importer les librairies graphiques que nous utiliserons dans ce chapitre, il faut faire"
      ],
      "id": "1761410b-5be2-442d-a974-78b6ddf9bd7e"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from plotnine import *"
      ],
      "id": "f5f9a762"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Comprendre, en quelques mots, le principe de `matplotlib`\n",
        "\n",
        "`matplotlib` date du début des années 2000 et a émergé pour proposer une alternative en `Python` à la création de graphiques sous `Matlab`, un logiciel propriétaire de calcul numérique. `matplotlib` est donc une librairie assez ancienne, antérieure à l’émergence de `Python` dans l’écosystème du traitement de données. Cela s’en ressent sur la logique de construction de `matplotlib` qui n’est pas toujours intuitive lorsqu’on est familier de l’écosystème moderne de la *data science*. Heureusement, il existe de nombreuses librairies qui s’appuient sur `matplotlib` mais qui visent à fournir une syntaxe plus familière aux *data scientists*.\n",
        "\n",
        "`matplotlib` propose principalement deux niveaux d’abstraction: la figure et les axes. La figure est, en quelque sorte, la “toile” globale qui contient un ou plusieurs axes dans lesquels s’inséreront des graphiques. Selon les cas, il faudra jouer avec les paramètres de figure ou d’axe, ce qui rend très flexible la construction d’un graphique mais peut également être déroutant car on ne sait jamais trop quel niveau d’abstraction il faut modifier pour mettre à jour sa figure[1]. Comme le montre la <a href=\"#fig-matplotlib\" class=\"quarto-xref\">Figure 2.1</a>, tous les éléments d’une figure sont paramétrables.\n",
        "\n",
        "<figure id=\"fig-matplotlib\">\n",
        "<img src=\"https://matplotlib.org/stable/_images/anatomy.png\" />\n",
        "<figcaption>Figure 2.1: Comprendre l’architecture d’une figure <code>matplotlib</code> (Source: <a href=\"https://matplotlib.org/stable/users/explain/quick_start.html\">documentation officielle</a>)</figcaption>\n",
        "</figure>\n",
        "\n",
        "En pratique, il existe deux manières de créer et mettre à jour sa figure selon qu’on préfère passer par:\n",
        "\n",
        "-   l’approche explicite, héritière d’une logique de programmation orientée objet, où on crée des objets `Figure` et `Axes` et met à jour ceux-ci.\n",
        "-   l’approche implicite, basée sur l’interface `pyplot` qui utilise une succession de fonctions pour mettre à jour les objets créés implicitement.\n",
        "\n",
        "## Approche explicite (approche orientée POO)\n",
        "\n",
        "``` python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(0, 2, 100)  # Sample data.\n",
        "\n",
        "# Note that even in the OO-style, we use `.pyplot.figure` to create the Figure.\n",
        "fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n",
        "ax.plot(x, x, label='linear')  # Plot some data on the Axes.\n",
        "ax.plot(x, x**2, label='quadratic')  # Plot more data on the Axes...\n",
        "ax.plot(x, x**3, label='cubic')  # ... and some more.\n",
        "ax.set_xlabel('x label')  # Add an x-label to the Axes.\n",
        "ax.set_ylabel('y label')  # Add a y-label to the Axes.\n",
        "ax.set_title(\"Simple Plot\")  # Add a title to the Axes.\n",
        "ax.legend()  # Add a legend.\n",
        "```\n",
        "\n",
        "Source: [Documentation officielle de `matplotlib`](https://matplotlib.org/stable/users/explain/quick_start.html)\n",
        "\n",
        "## Approche implicite\n",
        "\n",
        "``` python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.linspace(0, 2, 100)  # Sample data.\n",
        "\n",
        "plt.figure(figsize=(5, 2.7), layout='constrained')\n",
        "plt.plot(x, x, label='linear')  # Plot some data on the (implicit) Axes.\n",
        "plt.plot(x, x**2, label='quadratic')  # etc.\n",
        "plt.plot(x, x**3, label='cubic')\n",
        "plt.xlabel('x label')\n",
        "plt.ylabel('y label')\n",
        "plt.title(\"Simple Plot\")\n",
        "plt.legend()\n",
        "```\n",
        "\n",
        "Source: [Documentation officielle de `matplotlib`](https://matplotlib.org/stable/users/explain/quick_start.html)\n",
        "\n",
        "Ces éléments constituent le minimum pour comprendre la logique de `matplotlib`. Pour être plus à l’aise avec ces concepts, la pratique répétée est indispensable.\n",
        "\n",
        "## 2.2 Découvrir `matplotlib` par l’intermédiaire de `Pandas`\n",
        "\n",
        "Les 10 principales stations à l’issue de la question 1 représentent celles ayant la moyenne la plus élevée pour le volume de passages de vélos. Ces données réordonnées permettent de créer un graphique lisible et de mettre en avant les stations les plus fréquentées.\n",
        "\n",
        "[1] Thankfully, with a vast amount of online code using `matplotlib`, code assistants like `ChatGPT` or `Github Copilot` are invaluable for creating charts based on instructions."
      ],
      "id": "17874e8f-e316-433f-a16e-7ef406ba1e8e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<details>"
      ],
      "id": "db6b5e66-755b-4a7e-a648-20565d22f2de"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<summary>"
      ],
      "id": "25847b23-9d75-4252-bc16-92afeedae690"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Figure 1, sans travail sur le style, présente les données sous forme de *barplot* basique. Bien qu’elle montre les informations essentielles, elle manque de mise en page esthétique, de couleurs harmonieuses et d’annotations claires, nécessaires pour améliorer la lisibilité et l’impact visuel."
      ],
      "id": "b20eaca8-5214-47f5-bb2d-583eb3ffdcd4"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</summary>"
      ],
      "id": "625a659a-765d-4056-ba0a-c0b2b0966c07"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</details>"
      ],
      "id": "cbc0dd95-cc56-4d31-ae62-4f8bd0ce3f52"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Figure 2 sans travail sur le style:"
      ],
      "id": "ba193386-efb3-40d4-a93b-5bb9cc3b50ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On commence à avoir quelque chose qui commence à transmettre un message synthétique sur la nature des données. On peut néanmoins remarquer plusieurs éléments problématiques (par exemple les labels) mais aussi des éléments ne correspondant pas (les titres des axes, etc.) ou manquants (le nom du graphique…).\n",
        "\n",
        "Comme les graphiques produits par `Pandas` suivent la logique très flexible de `matplotlib`, il est possible de les customiser. Cependant, cela demande généralement beaucoup de travail et la grammaire `matplotlib` n’est pas aussi normalisée que celle de `ggplot` en `R`. Si on désire rester dans l’écosystème `matplotlib`, il est préférable de directement utiliser `seaborn`, qui offre quelques arguments prêts à l’emploi. Sinon on peut basculer sur l’écosystème `plotnine` qui offrira une syntaxe normalisée pour modifier les différents\n",
        "\n",
        "# 3. Utiliser directement `seaborn`\n",
        "\n",
        "## 3.1 Comprendre `seaborn` en quelques lignes\n",
        "\n",
        "`seaborn` est une interface haut niveau au dessus de `matplotlib`. Ce package offre un ensemble de fonctionnalités pour créer des figures ou des axes `matplotlib` directement depuis une fonction admettant de nombreux arguments et, si besoin d’aller plus loin dans la customisation, d’utiliser les fonctionnalités de `matplotlib` pour mettre à jour la figure, que ce soit par le biais de l’approche implicite ou explicite décrites précédemment.\n",
        "\n",
        "Comme pour `matplotlib`, `seaborn` permet de faire la même figure de multiples manières. `seaborn` hérite de la dualité axes-figures de `matplotlib` et il faudra souvent jouer avec un niveau ou l’autre. La principale caractéristique de `seaborn` est d’offrir quelques points d’entrée standardisés, par exemple `seaborn.relplot` ou `seaborn.catplot`, et une logique d’*inputs* basée sur le `DataFrame` là où `matplotlib` est structurée autour du *array* `Numpy`.\n",
        "\n",
        "La figure comporte maintenant un message mais il est encore peu lisible. Il y a plusieurs manières de faire un *barplot* en `seaborn`. Les deux principales sont :\n",
        "\n",
        "-   `sns.catplot` ;\n",
        "-   `sns.barplot`.\n",
        "\n",
        "On propose d’utiliser `sns.catplot` pour cet exercice. Il s’agit d’un point d’entrée assez fréquent pour faire des graphiques d’une variable discrétisée.\n",
        "\n",
        "## 3.2 Le diagramme en barre (*barplot*)\n",
        "\n",
        "À l’issue de la question 2, c’est-à-dire en utilisant `seaborn` pour reproduire de manière minimale un *barplot*, on obtient :\n",
        "\n",
        "Après quelques réglages esthétiques, à l’issue des questions 3 et 4, on obtient une figure proche de celle du portail *open data* parisien.\n",
        "\n",
        "Les paramètres supplémentaires proposés à la question 4 permettent finalement d’obtenir la figure\n",
        "\n",
        "On comprend ainsi que le boulevard de Sébastopol est le plus emprunté, ce qui ne vous surprendra pas si vous faites du vélo à Paris. Néanmoins, si vous n’êtes pas familiers avec la géographie parisienne, cela sera peu informatif pour vous, vous allez avoir besoin d’une représentation graphique supplémentaire : une carte ! Nous verrons ceci lors d’un prochain chapitre.\n",
        "\n",
        "## 3.3 Un exemple d’alternative au *barplot*, le *lollipop chart*\n",
        "\n",
        "Les diagrammes en bâtons (*barplot*) sont extrêmement communs, sans doute à cause de l’héritage d’Excel où ces graphiques sont faisables en deux clics. Néanmoins, en ce qui concerne le message à transmettre, ils sont loin d’être parfaits. Par exemple, les barres prennent beaucoup d’espace visuel, ce qui peut brouiller le message à transmettre sur le rapport entre les observations.\n",
        "\n",
        "Sur le plan sémiologique, c’est-à-dire sur le plan de l’efficacité du message à transmettre, les *lollipop charts* sont préférables : ils transmettent la même information mais avec moins de signes visuels pouvant brouiller sa compréhension.\n",
        "\n",
        "Les *lollipop charts* ne sont pas parfaits non plus mais sont un peu plus efficaces pour transmettre le message. Pour en savoir plus sur les alternatives au *barplot*, la conférence d’Eric Mauvière pour le réseau des *data scientists* de la statistique publique, dont le message principal est *“Désempilez vos figures”*, mérite le détour ([disponible sur le site ssphub.netlify.app/](https://ssphub.netlify.app/talk/2024-02-29-mauviere/)).\n",
        "\n",
        "# 4. La même figure avec `Plotnine`\n",
        "\n",
        "`plotnine` est le nouveau venu dans l’écosystème de la visualisation en `Python`. Cette librairie est développée par `Posit`, l’entreprise à l’origine de l’éditeur `RStudio` et de l’écosystème du *tidyverse* si central dans le langage `R`. Cette librairie vise à importer la logique de `ggplot` en `Python`, c’est-à-dire une grammaire des graphiques normalisée, lisible et flexible héritée de Wilkinson (2012).\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/elmo.jpg\" alt=\"L’état d’esprit des habitués de ggplot2 quand ils découvrent plotnine\" />\n",
        "<figcaption aria-hidden=\"true\">L’état d’esprit des habitués de <code>ggplot2</code> quand ils découvrent <code>plotnine</code></figcaption>\n",
        "</figure>\n",
        "\n",
        "Dans cette approche, un graphique est vu comme une succession de couches qui, une fois superposées, donneront la figure suivante. En soi, ce principe n’est pas différent de celui de `matplotlib`. Néanmoins, la grammaire utilisée par `plotnine` est beaucoup plus intuitive et normalisée, ce qui offrira beaucoup plus d’autonomie pour modifier sa figure.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://psyteachr.github.io/data-skills-v2/images/corsi/layers.png\" alt=\"La logique de ggplot (et plotnine) par Lisa (2021), image elle-même empruntée à Field (2012)\" />\n",
        "<figcaption aria-hidden=\"true\">La logique de <code>ggplot</code> (et <code>plotnine</code>) par <span class=\"citation\" data-cites=\"Lisa_psyTeachR_Book_Template_2021\">Lisa (2021)</span>, image elle-même empruntée à <span class=\"citation\" data-cites=\"field2012discovering\">Field (2012)</span></figcaption>\n",
        "</figure>\n",
        "\n",
        "Avec `plotnine`, il n’y a plus de point d’entrée dual figure-axe. Comme l’illustrent les slides ci-dessous :\n",
        "\n",
        "1.  On initialise une figure\n",
        "2.  On met à jour les couches (*layers*), un niveau d’abstraction très général concernant aussi bien les données représentées que les échelles des axes ou la couleur\n",
        "3.  À la fin, on peut jouer sur l’esthétique en modifiant les labels des axes, de la légende, les titres, etc.\n",
        "\n",
        "# 5. Premières agrégations temporelles\n",
        "\n",
        "On va maintenant se concentrer sur la dimension temporelle de notre jeu de données à travers deux approches :\n",
        "\n",
        "-   Un diagramme en barre synthétisant l’information de notre jeu de données de manière mensuelle ;\n",
        "-   Des séries instructives sur la dynamique temporelle. Cela sera l’objet de la prochaine partie.\n",
        "\n",
        "Avant cela, nous allons enrichir ces données pour bénéficier d’un historique plus long, permettant notamment d’avoir la période Covid dans nos données, ce qui présente un intérêt du fait de la dynamique particulière du trafic dans cette période (arrêt brutal, reprise très forte…)."
      ],
      "id": "bf68a901-294c-430a-86fa-9b7c8fd0d46b"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "list_useful_columns = [\n",
        "        \"Identifiant du compteur\", \"Nom du compteur\",\n",
        "        \"Identifiant du site de comptage\",\n",
        "        \"Nom du site de comptage\",\n",
        "        \"Comptage horaire\",\n",
        "        \"Date et heure de comptage\"\n",
        "    ]\n",
        "\n",
        "\n",
        "# GENERIC FUNCTION TO RETRIEVE DATA -------------------------\n",
        "\n",
        "\n",
        "def download_unzip_and_read(url, extract_to='.', list_useful_columns=list_useful_columns):\n",
        "    \"\"\"\n",
        "    Downloads a zip file from the specified URL, extracts its contents, and reads the CSV file based on the filename pattern in the URL.\n",
        "\n",
        "    Parameters:\n",
        "    - url (str): The URL of the zip file to download.\n",
        "    - extract_to (str): The directory where the contents of the zip file should be extracted.\n",
        "\n",
        "    Returns:\n",
        "    - df (DataFrame): The loaded pandas DataFrame from the extracted CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract the file pattern from the URL (filename without the extension)\n",
        "        file_pattern = url.split('/')[-1].replace('_zip/', '')\n",
        "\n",
        "\n",
        "        # Send a GET request to the specified URL to download the file\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure we get a successful response\n",
        "\n",
        "        # Create a ZipFile object from the downloaded bytes\n",
        "        with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "            # Extract all the contents to the specified directory\n",
        "            z.extractall(path=extract_to)\n",
        "            print(f\"Extracted all files to {os.path.abspath(extract_to)}\")\n",
        "\n",
        "        dir_extract_to = Path(extract_to)\n",
        "        #dir_extract_to = Path(f\"./{file_pattern}/\")\n",
        "\n",
        "        # Look for the file matching the pattern\n",
        "        csv_filename = [\n",
        "            f.name for f in dir_extract_to.iterdir() if f.suffix == '.csv'\n",
        "        ]\n",
        "\n",
        "        if not csv_filename:\n",
        "            print(f\"No file matching pattern '{file_pattern}' found.\")\n",
        "            return None\n",
        "\n",
        "        # Read the first matching CSV file into a pandas DataFrame\n",
        "        csv_path = os.path.join(dir_extract_to.name, csv_filename[0])\n",
        "        print(f\"Reading file: {csv_path}\")\n",
        "        df = pd.read_csv(csv_path, sep=\";\")\n",
        "\n",
        "        # CONVERT TO GEOPANDAS\n",
        "        df[['latitude', 'longitude']] = df['Coordonnées géographiques'].str.split(',', expand=True)\n",
        "        df['latitude'] = pd.to_numeric(df['latitude'])\n",
        "        df['longitude'] = pd.to_numeric(df['longitude'])\n",
        "        gdf = gpd.GeoDataFrame(\n",
        "            df, geometry=gpd.points_from_xy(df.longitude, df.latitude)\n",
        "        )\n",
        "\n",
        "        # CONVERT TO TIMESTAMP\n",
        "        df[\"Date et heure de comptage\"] = (\n",
        "            df[\"Date et heure de comptage\"]\n",
        "            .astype(str)\n",
        "            .str.replace(r'\\+.*', '', regex=True)\n",
        "        )\n",
        "        df[\"Date et heure de comptage\"] = pd.to_datetime(\n",
        "            df[\"Date et heure de comptage\"],\n",
        "            format=\"%Y-%m-%dT%H:%M:%S\",\n",
        "            errors=\"coerce\"\n",
        "        )\n",
        "        gdf = df.loc[\n",
        "            :, list_useful_columns\n",
        "        ]\n",
        "        return gdf\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: The downloaded file has not been found: {e}\")\n",
        "        return None\n",
        "    except zipfile.BadZipFile as e:\n",
        "        print(f\"Error: The downloaded file is not a valid zip file: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def read_historical_bike_data(year):\n",
        "    dataset = \"comptage_velo_donnees_compteurs\"\n",
        "    url_comptage = f\"https://opendata.paris.fr/api/datasets/1.0/comptage-velo-historique-donnees-compteurs/attachments/{year}_{dataset}_csv_zip/\"\n",
        "    df_comptage = download_unzip_and_read(\n",
        "        url_comptage, extract_to=f'./extracted_files_{year}'\n",
        "    )\n",
        "    if (df_comptage is None):\n",
        "        url_comptage_alternative = url_comptage.replace(\"_csv_zip\", \"_zip\")\n",
        "        df_comptage = download_unzip_and_read(url_comptage_alternative, extract_to=f'./extracted_files_{year}')\n",
        "    return df_comptage\n",
        "\n",
        "\n",
        "# IMPORT HISTORICAL DATA -----------------------------\n",
        "\n",
        "historical_bike_data = pd.concat(\n",
        "    [read_historical_bike_data(year) for year in range(2018, 2024)]\n",
        ")\n",
        "\n",
        "rename_columns_dict = {\n",
        "    \"Identifiant du compteur\": \"id_compteur\",\n",
        "    \"Nom du compteur\": \"nom_compteur\",\n",
        "    \"Identifiant du site de comptage\": \"id\",\n",
        "    \"Nom du site de comptage\": \"nom_site\",\n",
        "    \"Comptage horaire\": \"sum_counts\",\n",
        "    \"Date et heure de comptage\": \"date\"\n",
        "}\n",
        "\n",
        "\n",
        "historical_bike_data = historical_bike_data.rename(\n",
        "    columns=rename_columns_dict\n",
        ")\n",
        "\n",
        "\n",
        "# IMPORT LATEST MONTHS ----------------\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import duckdb\n",
        "\n",
        "url = 'https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/comptage-velo-donnees-compteurs/exports/parquet?lang=fr&timezone=Europe%2FParis'\n",
        "filename = 'comptage_velo_donnees_compteurs.parquet'\n",
        "\n",
        "\n",
        "# DOWNLOAD FILE --------------------------------\n",
        "\n",
        "# Perform the HTTP request and stream the download\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    # Perform the HTTP request and stream the download\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Get the total size of the file from the headers\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        # Open the file in write-binary mode and use tqdm to show progress\n",
        "        with open(filename, 'wb') as file, tqdm(\n",
        "                desc=filename,\n",
        "                total=total_size,\n",
        "                unit='B',\n",
        "                unit_scale=True,\n",
        "                unit_divisor=1024,\n",
        "        ) as bar:\n",
        "            # Write the file in chunks\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:  # filter out keep-alive chunks\n",
        "                    file.write(chunk)\n",
        "                    bar.update(len(chunk))\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "else:\n",
        "    print(f\"The file '{filename}' already exists.\")\n",
        "\n",
        "\n",
        "# READ FILE AND CONVERT TO PANDAS\n",
        "query = \"\"\"\n",
        "SELECT id_compteur, nom_compteur, id, sum_counts, date\n",
        "FROM read_parquet('comptage_velo_donnees_compteurs.parquet')\n",
        "\"\"\"\n",
        "\n",
        "# READ WITH DUCKDB AND CONVERT TO PANDAS\n",
        "df = duckdb.sql(query).df()\n",
        "\n",
        "df.head(3)\n",
        "\n",
        "\n",
        "# PUT THEM TOGETHER ----------------------------\n",
        "\n",
        "historical_bike_data['date'] = (\n",
        "    historical_bike_data['date']\n",
        "    .dt.tz_localize(None)\n",
        ")\n",
        "\n",
        "df[\"date\"] = df[\"date\"].dt.tz_localize(None)\n",
        "\n",
        "historical_bike_data = (\n",
        "    historical_bike_data\n",
        "    .loc[historical_bike_data[\"date\"] < df[\"date\"].min()]\n",
        ")\n",
        "\n",
        "df = pd.concat(\n",
        "    [historical_bike_data, df]\n",
        ")"
      ],
      "id": "download-bike-data-historical"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour commencer, reproduisons la troisième figure qui est, encore une fois, un *barplot*. Ici, sur le plan sémiologique, ce n’est pas justifié d’utiliser un *barplot*, une simple série suffirait à fournir une information similaire.\n",
        "\n",
        "La première question du prochain exercice implique une première rencontre avec une donnée temporelle à travers une opération assez classique en séries temporelles : changer le format d’une date pour pouvoir faire une agrégation à un pas de temps plus large.\n",
        "\n",
        "La figure avec les données depuis début 2022 aura cet aspect si elle a été construite avec `plotnine` :\n",
        "\n",
        "Avec `seaborn`, elle ressemblera plutôt à ceci :\n",
        "\n",
        "Si vous préférez représenter cela sous forme de *lollipop*[1]:\n",
        "\n",
        "Enfin, sur l’ensemble de la période, la série prendra plutôt cette forme :\n",
        "\n",
        "# 6. Première série temporelle\n",
        "\n",
        "Il est plus commun de représenter les données ayant une dimension temporelle sous la forme de série que de barres empilées.\n",
        "\n",
        ":\n",
        "\n",
        "# 7. Des graphiques réactifs grâce aux librairies `Javascript`\n",
        "\n",
        "## 7.1 L’écosystème disponible depuis `Python`\n",
        "\n",
        "Les figures figées construites avec `matplotlib` ou `plotnine` sont figées et présentent ainsi l’inconvénient de ne pas permettre d’interaction avec le lecteur. Toute l’information doit donc être contenue dans la figure, ce qui peut la rendre difficile à lire. Si la figure est bien faite, avec différents niveaux d’information, cela peut bien fonctionner.\n",
        "\n",
        "Il est néanmoins plus simple, grâce aux technologies *web*, de proposer des visualisations à plusieurs niveaux. Un premier niveau d’information, celui du coup d’œil, peut suffire à assimiler les principaux messages de la visualisation. Ensuite, un comportement plus volontaire de recherche d’information secondaire peut permettre d’en savoir plus. Les visualisations réactives, qui sont maintenant la norme dans le monde de la *dataviz*, permettent ce type d’approche : le lecteur d’une visualisation peut passer sa souris à la recherche d’informations complémentaires (par exemple, les valeurs exactes) ou cliquer pour faire apparaître des informations complémentaires sur la visualisation ou autour.\n",
        "\n",
        "Ces visualisations reposent sur le même triptyque que l’ensemble de l’écosystème *web* : `HTML`, `CSS` et `JavaScript`. Les utilisateurs de `Python` ne vont jamais manipuler directement ces langages, qui demandent une certaine expertise, mais vont utiliser des librairies au niveau de `R` qui génèreront automatiquement tout le code `HTML`, `CSS` et `JavaScript` permettant de créer la figure.\n",
        "\n",
        "Il existe plusieurs écosystèmes `Javascript` mis à disposition des développeurs.euses par le biais de `Python`. Les deux principales librairies sont [`Plotly`](https://plotly.com/python/), associée à l’écosystème `Javascript` du même nom, et [`Altair`](https://altair-viz.github.io/), associée à l’écosystème `Vega` et `Altair` en `Javascript`[2]. Pour permettre aux pythonistes de découvrir la librairie `Javascript` émergente [`Observable Plot`](https://observablehq.com/plot/), l’ingénieur de recherche français Julien Barnier a développé [`pyobsplot`](https://juba.github.io/pyobsplot/) une librairie `Python` permettant d’utiliser cet écosystème depuis `Python`.\n",
        "\n",
        "L’interactivité ne doit pas juste être un gadget n’apportant pas de lisibilité supplémentaire, voire la détériorant. Il est rare de pouvoir se contenter de la figure produite sans avoir à fournir un travail supplémentaire pour la rendre efficace.\n",
        "\n",
        "### 7.1.1 La librairie `Plotly`\n",
        "\n",
        "Le package `Plotly` est une surcouche à la librairie `Javascript` `Plotly.js` qui permet de créer et manipuler des objets graphiques de manière très flexible afin de produire des objets réactifs sans avoir à recourir à Javascript.\n",
        "\n",
        "Le point d’entrée recommandé est le module `plotly.express` ([documentation ici](https://plotly.com/python/plotly-express/)) qui offre une approche intuitive pour construire des graphiques pouvant être modifiés *a posteriori* si besoin (par exemple pour *customiser* les axes).\n",
        "\n",
        "## 7.2 Réplication de l’exemple précédent avec `Plotly`\n",
        "\n",
        "Les modules suivants seront nécessaires pour construire des graphiques avec `plotly`:\n",
        "\n",
        "[1] I removed the color on the y-axis as I find it adds little to the figure and may even degrade the clarity of the message.\n",
        "\n",
        "[2] The names of these libraries are inspired by the Summer Triangle constellation, of which Vega and Altair are two members."
      ],
      "id": "7a264d7f-6ba0-47be-9a33-6b3719506aec"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.express as px"
      ],
      "id": "e25c3691"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.3 La librairie `altair`\n",
        "\n",
        "Pour cet exemple, nous allons reconstruire notre figure précédente.\n",
        "\n",
        "Comme `ggplot`/`plotnine`, `Vega` est un écosystème graphique visant à proposer une implémentation de la grammaire des graphiques de Wilkinson (2012). La syntaxe de `Vega` est donc basée sur un principe déclaratif : on déclare une construction par couches et transformations de données progressives.\n",
        "\n",
        "À l’origine, `Vega` est basée sur une syntaxe JSON, d’où son lien fort avec `Javascript`. Néanmoins, il existe une API Python qui permet de faire ce type de figures interactives nativement en Python. Pour comprendre la logique de construction d’un code `altair`, voici comment répliquer la figure précédente avec :"
      ],
      "id": "aa3a28e8-7201-4236-9f9a-2469f980c6ff"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "import altair as alt\n",
        "\n",
        "color_scale = alt.Scale(domain=[True, False], range=['green', 'red'])\n",
        "\n",
        "fig2 = (\n",
        "    alt.Chart(df1)\n",
        "    .mark_bar()\n",
        "    .encode(\n",
        "        x=alt.X('average(sum_counts):Q', title='Moyenne du comptage par heure sur la période sélectionnée'),\n",
        "        y=alt.Y('nom_compteur:N', sort='-x', title=''),\n",
        "        color=alt.Color('top:N', scale=color_scale, legend=alt.Legend(title=\"Top\")),\n",
        "        tooltip=[\n",
        "            alt.Tooltip('nom_compteur:N', title='Nom du compteur'),\n",
        "            alt.Tooltip('sum_counts:Q', title='Moyenne horaire')\n",
        "            ]\n",
        "    ).properties(\n",
        "        title='Les 10 compteurs avec la moyenne horaire la plus élevée'\n",
        "    ).configure_view(\n",
        "        strokeOpacity=0\n",
        "    )\n",
        ")\n",
        "\n",
        "fig2.interactive()"
      ],
      "id": "2f2671a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Field, A. 2012. « Discovering Statistics Using R ». Sage.\n",
        "\n",
        "Lisa, DeBruine. 2021. « psyTeachR Book Template ». <https://github.com/psyteachr/template/>.\n",
        "\n",
        "Wilkinson, Leland. 2012. *The grammar of graphics*. Springer."
      ],
      "id": "953d7eb6-a522-4cf3-b86a-eeecf73fa0fa"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/runner/work/python-datascientist/python-datascientist/.venv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  }
}